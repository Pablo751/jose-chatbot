# chatbot_app.py

import streamlit as st
import pandas as pd
from sentence_transformers import SentenceTransformer
import faiss
from typing import Dict, List
import numpy as np
import re
import logging
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler
import threading
import time
from nltk.stem import SnowballStemmer
from nltk.corpus import stopwords
import nltk
import openai
import os

# -------------------------------
# Configurar el Logging
# -------------------------------
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Descargar recursos de NLTK si no est√°n presentes
nltk.download('stopwords')

# -------------------------------
# 1. Configurar la Aplicaci√≥n Streamlit
# -------------------------------

st.set_page_config(
    page_title="üí¨ Asistente de Productos",
    page_icon="üí¨",
    layout="wide",
    initial_sidebar_state="expanded",
)

st.title("üí¨ Asistente de Productos")

# -------------------------------
# 2. Configurar el Cliente de OpenAI
# -------------------------------
openai.api_key = st.secrets["OPENAI_API_KEY"]

def call_gpt4o(prompt: str, max_tokens: int = 500) -> str:
    """
    Llama a la API de OpenAI GPT-4o para generar una respuesta basada en el prompt.
    """
    try:
        response = openai.ChatCompletion.create(
            model="gpt-4o-2024-08-06",  # Aseg√∫rate de usar la versi√≥n correcta
            messages=[
                {"role": "system", "content": """
                Eres un asistente de ventas que ayuda a los clientes a encontrar productos en nuestra tienda.
                Utiliza √∫nicamente la informaci√≥n proporcionada sobre el producto para responder. No inventes ni agregues detalles adicionales.
                """},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,  # Baja temperatura para respuestas m√°s precisas
            max_tokens=max_tokens,
            n=1,
            stop=None,
        )
        return response.choices[0].message.content.strip()
    except openai.error.OpenAIError as e:
        logger.error(f"Error al llamar a GPT-4o: {e}")
        return "Lo siento, ocurri√≥ un error al generar la respuesta. Por favor, int√©ntalo de nuevo m√°s tarde."

# -------------------------------
# 3. Cargar y Preprocesar Datos
# -------------------------------

@st.cache_data(show_spinner=False)
def load_product_data(file_path: str) -> pd.DataFrame:
    """
    Carga y preprocesa los datos de productos con solo las columnas esenciales.
    Filtra productos con precio mayor a 0.
    """
    columns_to_load = ['sku', 'name', 'description', 'short_description', 'price', 
                       'additional_attributes', 'base_image', 'url_key']
    df = pd.read_csv(file_path, usecols=columns_to_load)
    
    # Limpiar y rellenar valores nulos
    df.fillna({'additional_attributes': 'Informaci√≥n no disponible', 
              'short_description': 'Informaci√≥n no disponible',
              'description': 'Informaci√≥n no disponible',
              'price': 0.0,
              'base_image': '',
              'url_key': '#'}, inplace=True)
    
    # Filtrar productos con precio > 0
    df = df[df['price'] > 0.0].reset_index(drop=True)
    
    return df

def validate_csv(df: pd.DataFrame) -> bool:
    """
    Valida que el DataFrame tenga las columnas esenciales y que no falten datos cr√≠ticos.
    """
    expected_columns = ['sku', 'name', 'description', 'short_description', 'price', 
                        'additional_attributes', 'base_image', 'url_key']
    if not all(column in df.columns for column in expected_columns):
        st.error("El CSV no contiene todas las columnas requeridas.")
        return False
    
    # Verificar valores nulos en columnas esenciales (despu√©s de rellenar)
    essential_columns = ['sku', 'name', 'price']
    if df[essential_columns].isnull().any().any():
        st.warning("Algunos productos tienen informaci√≥n incompleta en campos esenciales. Revisar el CSV.")
    
    return True

# Cargar datos
product_file = 'data/jose.csv'
try:
    product_data = load_product_data(product_file)
    if not validate_csv(product_data):
        st.stop()
    st.sidebar.success("‚úÖ Cat√°logo de productos cargado correctamente")
    logger.info(f"Productos cargados: {len(product_data)}")
except Exception as e:
    st.error(f"Error al cargar el cat√°logo de productos: {e}")
    logger.error(f"Error al cargar el cat√°logo de productos: {e}")
    st.stop()

# -------------------------------
# 4. Generar Embeddings y Configurar FAISS
# -------------------------------

@st.cache_resource(show_spinner=False)
def generate_embeddings_faiss_ivf(df: pd.DataFrame, model_name: str = 'all-MiniLM-L6-v2', nlist: int = 50) -> (np.ndarray, faiss.Index):
    """
    Genera embeddings para los productos y configura el √≠ndice FAISS IVFFlat para mayor escalabilidad.
    """
    model = SentenceTransformer(model_name)
    # Concatenar campos relevantes para generar el embedding
    texts = df['name'] + " " + df['description'] + " " + df['short_description']
    embeddings = model.encode(texts.tolist(), show_progress_bar=True)
    
    # Normalizar embeddings
    faiss.normalize_L2(embeddings)
    
    # Crear √≠ndice FAISS IVFFlat
    dimension = embeddings.shape[1]
    quantizer = faiss.IndexFlatIP(dimension)  # Cuantizador para el √≠ndice IVFFlat
    index = faiss.IndexIVFFlat(quantizer, dimension, nlist, faiss.METRIC_INNER_PRODUCT)
    
    # Entrenar el √≠ndice con un subconjunto de embeddings
    if not index.is_trained:
        logger.info("Entrenando el √≠ndice FAISS...")
        index.train(embeddings)
    
    index.add(embeddings)
    
    return embeddings, index

try:
    embeddings, faiss_index = generate_embeddings_faiss_ivf(product_data)
    logger.info("Embeddings generados y FAISS index configurado.")
except Exception as e:
    st.error(f"Error al generar embeddings: {e}")
    logger.error(f"Error al generar embeddings: {e}")
    st.stop()

# -------------------------------
# 5. Implementaci√≥n del Monitoreo de Cambios en el CSV
# -------------------------------

class CSVChangeHandler(FileSystemEventHandler):
    def __init__(self, file_path):
        self.file_path = file_path
    
    def on_modified(self, event):
        if event.src_path.endswith(self.file_path):
            logger.info(f"Archivo {self.file_path} modificado.")
            st.session_state['file_changed'] = True

def start_file_watcher(file_path: str):
    event_handler = CSVChangeHandler(file_path)
    observer = Observer()
    observer.schedule(event_handler, path='.', recursive=False)
    observer.start()
    logger.info("Watcher iniciado.")
    try:
        while True:
            time.sleep(1)
    except KeyboardInterrupt:
        observer.stop()
    observer.join()

# -------------------------------
# 6. Funciones de B√∫squeda y Coincidencia
# -------------------------------

def extract_search_terms(user_query: str) -> List[str]:
    """
    Extrae t√©rminos relevantes de b√∫squeda de la consulta del usuario.
    Implementaci√≥n mejorada con lematizaci√≥n y eliminaci√≥n de stop words.
    """
    # Convertir a min√∫sculas
    user_query = user_query.lower()
    # Remover caracteres especiales
    user_query = re.sub(r'[^\w\s]', '', user_query)
    # Tokenizar
    terms = user_query.split()
    # Filtrar palabras irrelevantes usando NLTK
    stop_words = set(stopwords.words('spanish')).union({'puedes', 'recomendar', 'economico', 'econ√≥mico', 'por', 'que', 'puedo', 'tienes', 'tenes'})
    filtered_terms = [term for term in terms if term not in stop_words]
    # Lematizaci√≥n
    stemmer = SnowballStemmer('spanish')
    lemmatized_terms = [stemmer.stem(term) for term in filtered_terms]
    logger.info(f"T√©rminos de b√∫squeda extra√≠dos: {lemmatized_terms}")
    return lemmatized_terms

def search_products_faiss(query: str, model: SentenceTransformer, index: faiss.Index, df: pd.DataFrame, top_k: int = 5) -> List[Dict]:
    """
    Busca productos que coincidan con la consulta utilizando FAISS y embeddings.
    """
    try:
        if not query.strip():
            logger.warning("Consulta vac√≠a despu√©s de filtrar stop words.")
            return []
        
        # Generar embedding para la consulta
        query_embedding = model.encode([query], normalize_embeddings=True)
        # Realizar b√∫squeda en el √≠ndice FAISS
        D, I = index.search(query_embedding, top_k)
        results = []
        for distance, idx in zip(D[0], I[0]):
            if distance > 0:  # Similaridad positiva
                product = df.iloc[idx].to_dict()
                results.append({'product': product, 'score': distance})
        logger.info(f"Productos encontrados: {len(results)}")
        return results
    except Exception as e:
        logger.error(f"Error durante la b√∫squeda de productos: {e}")
        st.error("Ocurri√≥ un error durante la b√∫squeda de productos. Por favor, int√©ntalo de nuevo m√°s tarde.")
        return []

def format_features(features: str) -> str:
    """
    Formatea las caracter√≠sticas del producto como una lista con vi√±etas.
    """
    if features == 'Informaci√≥n no disponible':
        return features
    feature_pairs = [attr.split('=') for attr in features.split(',') if '=' in attr]
    feature_list = '\n'.join([f"- **{k.strip()}**: {v.strip()}" for k, v in feature_pairs])
    return feature_list

def generate_product_response(product_info: Dict[str, str]) -> str:
    """
    Genera una respuesta personalizada utilizando GPT-4o basada √∫nicamente en la informaci√≥n del producto.
    """
    # Formatear el precio
    try:
        price = float(product_info.get('price', 0.0))
        price_formatted = f"${price:,.2f}"
    except:
        price_formatted = "Informaci√≥n no disponible"
    
    # Formatear caracter√≠sticas
    features_formatted = format_features(product_info.get('additional_attributes', 'Informaci√≥n no disponible'))
    
    # URL del producto
    url_key = product_info.get('url_key', '#')
    product_url = f"https://tutienda.com/product/{url_key}"  # Reemplaza con la URL base de tu tienda
    
    # Imagen del producto
    base_image = product_info.get('base_image', '')
    if base_image and isinstance(base_image, str):
        image_url = f"https://tutienda.com/{base_image}"  # Reemplaza con la URL base de tus im√°genes
    else:
        image_url = "https://via.placeholder.com/150"  # Imagen por defecto
    
    # Crear un resumen de la informaci√≥n del producto para el prompt
    product_summary = f"""
    Nombre del Producto: {product_info.get('name', 'Informaci√≥n no disponible')}
    Descripci√≥n: {product_info.get('short_description', 'Informaci√≥n no disponible')}
    Precio: {price_formatted}
    Caracter√≠sticas:
    {features_formatted}
    URL del Producto: {product_url}
    Imagen del Producto: {image_url}
    """
    
    # Crear el prompt para GPT-4o
    prompt = f"""
    Utilizando √∫nicamente la siguiente informaci√≥n sobre el producto, genera una descripci√≥n conversacional y atractiva para el cliente:

    {product_summary}
    """
    
    # Llamar a GPT-4o para generar la respuesta
    response = call_gpt4o(prompt, max_tokens=500)
    
    return response

# -------------------------------
# 7. Implementaci√≥n de Feedback del Usuario
# -------------------------------

def add_feedback(product_name: str, feedback: str):
    """
    Almacena el feedback del usuario para un producto espec√≠fico.
    """
    feedback_file = 'data/feedback.csv'
    new_feedback = {'product_name': product_name, 'feedback': feedback}
    try:
        if os.path.exists(feedback_file):
            df_feedback = pd.read_csv(feedback_file)
            df_feedback = df_feedback.append(new_feedback, ignore_index=True)
        else:
            df_feedback = pd.DataFrame([new_feedback])
    except Exception as e:
        logger.error(f"Error al agregar feedback: {e}")
        st.error("Ocurri√≥ un error al guardar tu feedback. Por favor, int√©ntalo de nuevo m√°s tarde.")
        return
    df_feedback.to_csv(feedback_file, index=False)
    logger.info(f"Feedback agregado para producto: {product_name}")
    st.success("¬°Gracias por tu feedback!")

# -------------------------------
# 8. Funci√≥n para Iniciar el Watcher en un Hilo Separado
# -------------------------------

# Iniciar el watcher en un hilo separado para no bloquear la interfaz
if 'watcher_started' not in st.session_state:
    watcher_thread = threading.Thread(target=start_file_watcher, args=(product_file,), daemon=True)
    watcher_thread.start()
    st.session_state['watcher_started'] = True

# -------------------------------
# 9. Interfaz Principal con Soporte de Follow-Up
# -------------------------------

# Inicializar historial de conversaci√≥n y contexto del producto
if 'conversation' not in st.session_state:
    st.session_state['conversation'] = []
if 'current_product' not in st.session_state:
    st.session_state['current_product'] = None  # Producto actual para preguntas de seguimiento

# Verificar si el archivo ha cambiado y recargar los datos
if 'file_changed' in st.session_state and st.session_state['file_changed']:
    try:
        product_data = load_product_data(product_file)
        if not validate_csv(product_data):
            st.stop()
        faiss_index = generate_embeddings_faiss_ivf(product_data)[1]
        st.sidebar.success("‚úÖ Cat√°logo de productos recargado correctamente")
        logger.info(f"Productos recargados: {len(product_data)}")
        st.session_state['file_changed'] = False
    except Exception as e:
        st.error(f"Error al recargar el cat√°logo de productos: {e}")
        logger.error(f"Error al recargar el cat√°logo de productos: {e}")
        st.stop()

# Entrada del usuario
st.write("üëã ¬°Hola! Soy tu asistente de productos. ¬øEn qu√© puedo ayudarte?")
user_question = st.text_input("Escribe tu pregunta aqu√≠:", key="user_input")

# Bot√≥n para enviar la pregunta
if st.button("Enviar Pregunta"):
    if not user_question.strip():
        st.warning("Por favor, ingresa una pregunta.")
    else:
        with st.spinner("Buscando la mejor respuesta..."):
            # Extraer t√©rminos de b√∫squeda
            search_terms = extract_search_terms(user_question)
            st.write(f"üîç **T√©rminos de B√∫squeda:** {', '.join(search_terms)}")  # Mostrar t√©rminos extra√≠dos
            
            # Reconstruir la consulta sin stop words para generar una b√∫squeda m√°s efectiva
            reconstructed_query = ' '.join(search_terms)
            
            # Cargar el modelo para generar embeddings de la consulta
            model = SentenceTransformer('all-MiniLM-L6-v2')
            
            # Buscar productos relevantes usando FAISS
            matches = search_products_faiss(reconstructed_query, model, faiss_index, product_data, top_k=5)
            
            if matches:
                # Usar el producto m√°s relevante para generar la respuesta
                best_match = matches[0]['product']
                
                # Verificar si esta es una pregunta de seguimiento
                if st.session_state['current_product'] and "m√°s" in user_question.lower():
                    # Utilizar el mismo producto para la pregunta de seguimiento
                    response = generate_product_response(st.session_state['current_product'])
                else:
                    # Actualizar el producto actual en el estado de sesi√≥n
                    st.session_state['current_product'] = best_match
                    response = generate_product_response(best_match)
                
                # Agregar al historial
                st.session_state['conversation'].append({
                    "question": user_question,
                    "response": response,
                    "product": best_match['name']
                })
                
                # Mostrar la respuesta utilizando Markdown para un mejor formato
                st.markdown(response)
                
                # Mostrar productos alternativos con feedback
                if len(matches) > 1:
                    st.write("üìå **Tambi√©n podr√≠an interesarte estos productos:**")
                    for match in matches[1:]:
                        product = match['product']
                        # Formatear el precio
                        try:
                            price = float(product.get('price', 0.0))
                            price_formatted = f"${price:,.2f}"
                        except:
                            price_formatted = "Informaci√≥n no disponible"
                        # URL del producto
                        url_key = product.get('url_key', '#')
                        product_url = f"https://tutienda.com/product/{url_key}"  # Reemplaza con la URL base de tu tienda
                        st.write(f"- [{product['name']}]({product_url}) - {price_formatted}")
                        
                        # Botones de feedback
                        feedback = st.radio(
                            f"¬øTe gust√≥ la recomendaci√≥n de {product['name']}?",
                            options=["S√≠", "No"],
                            key=f"feedback_{product['sku']}"
                        )
                        if st.button(f"Enviar Feedback para {product['sku']}", key=f"feedback_btn_{product['sku']}"):
                            add_feedback(product['name'], feedback)
            else:
                response = "Lo siento, no encontr√© productos que coincidan con tu consulta. ¬øPodr√≠as reformular tu pregunta?"
                st.session_state['conversation'].append({
                    "question": user_question,
                    "response": response,
                    "product": None
                })
                st.markdown(f"**Respuesta:** {response}")

# Mostrar historial de conversaci√≥n
if st.session_state['conversation']:
    st.write("### Historial de Conversaci√≥n")
    for i, entry in enumerate(reversed(st.session_state['conversation']), 1):
        st.write(f"**Pregunta {i}:** {entry['question']}")
        st.markdown(f"**Respuesta {i}:** {entry['response']}")
        if entry['product']:
            st.write(f"*Producto relacionado: {entry['product']}*")
        st.markdown("---")

# Bot√≥n para limpiar historial y resetear producto actual
if st.button("Limpiar Historial"):
    st.session_state['conversation'] = []
    st.session_state['current_product'] = None
    st.experimental_rerun()
