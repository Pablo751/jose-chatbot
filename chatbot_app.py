import streamlit as st
import pandas as pd
from sentence_transformers import SentenceTransformer
import faiss
from typing import Dict, List, Tuple, Optional
import numpy as np
import re
import logging
from nltk.stem import SnowballStemmer
from nltk.corpus import stopwords
import nltk
import openai  # Corregido

# Configuraci√≥n de logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Descargar recursos de NLTK
nltk.download('stopwords')

class ProductAssistant:
    def __init__(self, api_key: str):
        """Inicializa el asistente de productos."""
        openai.api_key = api_key  # Corregido
        self.categories = {}
        self.product_data = None
        self.embeddings = None
        self.faiss_index = None
        self.model = SentenceTransformer('all-MiniLM-L6-v2')
        
    def load_data(self, df: pd.DataFrame):
        """Carga y procesa los datos de productos."""
        # Verificar columnas necesarias
        required_columns = ['name', 'description', 'short_description', 'price', 'categories']
        for col in required_columns:
            if col not in df.columns:
                logger.error(f"Falta la columna requerida: {col}")
                raise ValueError(f"Falta la columna requerida: {col}")
        
        # Manejar valores faltantes y tipos de datos
        df['price'] = pd.to_numeric(df['price'], errors='coerce').fillna(0)
        df['categories'] = df['categories'].fillna('Default Category')
        df['name'] = df['name'].fillna('Nombre Desconocido')
        df['description'] = df['description'].fillna('')
        df['short_description'] = df['short_description'].fillna('')
        
        self.product_data = df
        self._extract_categories()
        self._generate_embeddings()
        
    def _extract_categories(self):
        """Extrae y simplifica las categor√≠as."""
        main_categories = set()
        for _, row in self.product_data.iterrows():
            categories = str(row['categories']).split(',')
            for category in categories:
                parts = category.strip().split('/')
                # Tomar solo la categor√≠a principal despu√©s de "Default Category"
                for i, part in enumerate(parts):
                    if part.strip() == "Default Category" and i + 1 < len(parts):
                        main_categories.add(parts[i + 1].strip())
        
        # Organizar en diccionario
        self.categories = {cat: {} for cat in main_categories}
    
    def _generate_embeddings(self):
        """Genera embeddings para los productos."""
        texts = (self.product_data['name'] + " " + 
                self.product_data['description'] + " " + 
                self.product_data['short_description'])
        self.embeddings = self.model.encode(texts.tolist(), show_progress_bar=True)
        faiss.normalize_L2(self.embeddings)
        
        dimension = self.embeddings.shape[1]
        self.faiss_index = faiss.IndexFlatIP(dimension)
        self.faiss_index.add(self.embeddings)

    def search_products(self, 
                       query: str, 
                       category: Optional[str] = None, 
                       max_price: Optional[float] = None,
                       top_k: int = 5) -> List[Dict]:
        """B√∫squeda mejorada de productos con manejo correcto de √≠ndices."""
        try:
            # Crear una copia del DataFrame para no modificar el original
            filtered_df = self.product_data.copy()
            
            # Aplicar filtros y validar que haya datos
            if category:
                category_mask = filtered_df['categories'].str.contains(category, na=False, regex=False)
                filtered_df = filtered_df[category_mask].reset_index(drop=True)
            if max_price:
                filtered_df['price'] = pd.to_numeric(filtered_df['price'], errors='coerce')
                price_mask = filtered_df['price'] < max_price
                filtered_df = filtered_df[price_mask].reset_index(drop=True)
            
            # Verificar si hay resultados despu√©s del filtrado
            if filtered_df.empty:
                logger.warning("No hay productos que cumplan con los filtros")
                return []
            
            logger.info(f"Number of products after filtering: {len(filtered_df)}")
            
            # Generar embedding para la consulta
            query_embedding = self.model.encode([query], show_progress_bar=False)
            faiss.normalize_L2(query_embedding)
            
            # Generar textos para los productos filtrados
            texts = []
            for _, row in filtered_df.iterrows():
                text = f"{row['name']} "
                if pd.notna(row.get('description')):
                    text += f"{row['description']} "
                if pd.notna(row.get('short_description')):
                    text += f"{row['short_description']}"
                texts.append(text.strip())
            
            # Verificar si hay textos para procesar
            if not texts:
                logger.warning("No hay textos para procesar")
                return []
                
            # Generar embeddings para los textos filtrados
            filtered_embeddings = self.model.encode(texts, show_progress_bar=False)
            faiss.normalize_L2(filtered_embeddings)
            
            # Verificar la correspondencia entre embeddings y DataFrame
            if len(filtered_embeddings) != len(filtered_df):
                logger.error("Mismatch entre el n√∫mero de embeddings y el DataFrame filtrado.")
                return []
            
            # Crear √≠ndice temporal de FAISS
            temp_index = faiss.IndexFlatIP(filtered_embeddings.shape[1])
            temp_index.add(filtered_embeddings)
            
            logger.info(f"Performing FAISS search with top_k={top_k}")
            
            results = []
            if len(filtered_embeddings) > 0:
                k = min(top_k, len(filtered_df))
                if k == 0:
                    return []
                    
                # Realizar b√∫squeda
                D, I = temp_index.search(query_embedding, k)
                
                logger.info(f"FAISS returned distances: {D}")
                logger.info(f"FAISS returned indices: {I}")
                
                # Verificar y procesar los resultados
                if len(D) > 0 and len(D[0]) > 0:
                    for distance, idx in zip(D[0], I[0]):
                        logger.debug(f"Processing index: {idx} with distance: {distance}")
                        
                        # Verificar que el √≠ndice est√° dentro del rango
                        if 0 <= idx < len(filtered_df):
                            try:
                                product = filtered_df.iloc[idx].to_dict()
                                price = pd.to_numeric(product['price'], errors='coerce')
                                if pd.notna(price) and price > 0:
                                    results.append({
                                        'product': product,
                                        'score': float(distance),
                                        'query': query
                                    })
                                else:
                                    logger.warning(f"Producto con √≠ndice {idx} tiene un precio inv√°lido.")
                            except Exception as e:
                                logger.error(f"Error procesando producto {idx}: {e}")
                                continue
                        else:
                            logger.error(f"√çndice FAISS {idx} est√° fuera de los l√≠mites del DataFrame filtrado.")
            
            logger.info(f"Number of products found: {len(results)}")
            return results
            
        except Exception as e:
            logger.error(f"Error en b√∫squeda de productos: {e}")
            return []
    
    def process_query_with_context(self, 
                                 query: str, 
                                 previous_results: Optional[List[Dict]] = None) -> Tuple[List[Dict], str]:
        """Procesa la consulta considerando el contexto anterior."""
        try:
            if not query.strip():
                return [], "Por favor, hazme una pregunta sobre los productos."
            
            # Detectar si es una pregunta sobre precio
            price_related = re.search(r'm√°s barato|m√°s econ√≥mico|menor precio|barato|econ√≥mico', query.lower()) is not None
            
            if price_related and previous_results and len(previous_results) > 0:
                prev_product = previous_results[0].get('product')
                if not prev_product:
                    return [], "No encontr√© el producto anterior. ¬øPodr√≠as repetir tu pregunta inicial?"
                
                try:
                    prev_price = float(prev_product['price'])
                except (ValueError, TypeError):
                    return [], "Hubo un problema con el precio del producto anterior. ¬øPodr√≠as hacer tu pregunta de nuevo?"
                
                # Extraer categor√≠a del producto anterior
                prev_category = None
                if 'categories' in prev_product:
                    categories = str(prev_product['categories']).split(',')
                    if categories:
                        # Tomar la categor√≠a m√°s espec√≠fica (√∫ltima)
                        prev_category = categories[-1].strip()
                
                # Buscar productos m√°s baratos
                results = self.search_products(
                    query=previous_results[0].get('query', ''),  # Usar la consulta original
                    category=prev_category,
                    max_price=prev_price * 0.95,  # 5% m√°s barato
                    top_k=5
                )
                
                if results:
                    response = self._generate_comparative_response(
                        query=query,
                        prev_product=prev_product,
                        new_product=results[0]['product']
                    )
                    return results, response
                else:
                    return [], f"No encontr√© productos m√°s econ√≥micos que el {prev_product['name']} (${prev_price:,.2f}). ¬øTe gustar√≠a ver alternativas en otra categor√≠a?"
            
            # B√∫squeda normal
            results = self.search_products(query)
            if not results:
                return [], "No encontr√© productos que coincidan con tu b√∫squeda. ¬øPodr√≠as darme m√°s detalles sobre lo que buscas?"
            
            response = self._generate_response(query, results[0]['product'])
            return results, response
            
        except Exception as e:
            logger.error(f"Error procesando consulta: {e}")
            return [], "Lo siento, ocurri√≥ un error. ¬øPodr√≠as reformular tu pregunta?"
    
    
    def _generate_response(self, query: str, product: Dict) -> str:
        """Genera una respuesta para un producto."""
        try:
            prompt = f"""
            Como asistente de ventas experto, responde a esta consulta:
            
            Consulta: {query}
            
            Producto:
            Nombre: {product['name']}
            Precio: ${float(product['price']):,.2f}
            Descripci√≥n: {product.get('short_description', '')}
            Caracter√≠sticas: {product.get('additional_attributes', '')}
            """
            
            # Usar OpenAI correctamente
            response = openai.ChatCompletion.create(
                model="chatgpt-4o-latest",  # Mantener seg√∫n solicitud del usuario
                messages=[
                    {"role": "system", "content": "Eres un experto en productos el√©ctricos que ayuda a los clientes."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7
            )
            return response.choices[0].message.content
        except Exception as e:
            logger.error(f"Error en GPT: {e}")
            return f"Te recomiendo el {product['name']} que cuesta ${float(product['price']):,.2f}."
    
    
    def _generate_comparative_response(self, query: str, prev_product: Dict, new_product: Dict) -> str:
        """Genera una respuesta comparativa entre productos."""
        try:
            savings = float(prev_product['price']) - float(new_product['price'])
            
            prompt = f"""
            Como experto en ventas, compara estos productos respondiendo a: {query}
    
            Producto anterior:
            Nombre: {prev_product['name']}
            Precio: ${float(prev_product['price']):,.2f}
            Caracter√≠sticas: {prev_product.get('additional_attributes', '')}
    
            Producto nuevo (m√°s econ√≥mico):
            Nombre: {new_product['name']}
            Precio: ${float(new_product['price']):,.2f}
            Ahorro: ${savings:,.2f}
            Caracter√≠sticas: {new_product.get('additional_attributes', '')}
            """
    
            response = openai.ChatCompletion.create(
                model="chatgpt-4o-latest",  # Mantener seg√∫n solicitud del usuario
                messages=[
                    {"role": "system", "content": "Eres un experto en productos el√©ctricos especializado en encontrar las mejores ofertas."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7
            )
            return response.choices[0].message.content
        except Exception as e:
            logger.error(f"Error generando respuesta comparativa: {e}")
            return f"He encontrado el {new_product['name']} a ${float(new_product['price']):,.2f}, " \
                   f"que te permite ahorrar ${savings:,.2f} comparado con la opci√≥n anterior."


def main():
    st.set_page_config(
        page_title="üí¨ Asistente de Productos",
        page_icon="üí¨",
        layout="wide"
    )

    st.title("üí¨ Asistente de Productos")
    
    # Inicializar estado
    if 'assistant' not in st.session_state:
        assistant = ProductAssistant(st.secrets["OPENAI_API_KEY"])
        try:
            product_data = pd.read_csv('data/jose.csv')
            assistant.load_data(product_data)
            st.session_state['assistant'] = assistant
            st.session_state['previous_results'] = None
            st.session_state['conversation_history'] = []
            logger.info("Datos de productos cargados exitosamente.")
        except Exception as e:
            logger.error(f"Error cargando datos de productos: {e}")
            st.error("Hubo un error al cargar los datos de productos. Por favor, revisa los logs.")

    # Input del usuario
    user_question = st.text_input("¬øEn qu√© puedo ayudarte?")
    
    if st.button("Enviar"):
        if user_question:
            # Procesar consulta con contexto
            results, response = st.session_state['assistant'].process_query_with_context(
                user_question,
                st.session_state.get('previous_results')
            )
            
            # Actualizar contexto
            st.session_state['previous_results'] = results
            
            # Guardar en historial
            st.session_state['conversation_history'].append({
                'question': user_question,
                'response': response,
                'results': results
            })
            
            # Mostrar respuesta
            st.markdown("### ü§ñ Respuesta:")
            st.write(response)
            
            if results:
                st.markdown("### üì¶ Productos encontrados:")
                for result in results:
                    product = result['product']
                    st.markdown(f"""
                    **{product['name']}**
                    - üí∞ Precio: ${float(product['price']):,.2f}
                    - üìë Categor√≠a: {product.get('categories', '').split(',')[0]}
                    """)
    
    # Mostrar historial
    if st.session_state.get('conversation_history'):
        st.markdown("---\n### üìù Historial de Conversaci√≥n")
        for i, entry in enumerate(reversed(st.session_state['conversation_history'])):
            with st.expander(f"Conversaci√≥n {len(st.session_state['conversation_history'])-i}"):
                st.markdown(f"**üë§ Pregunta:** {entry['question']}")
                st.markdown(f"**ü§ñ Respuesta:** {entry['response']}")

if __name__ == "__main__":
    main()
